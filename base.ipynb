{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[Dataset](https://archive-beta.ics.uci.edu/dataset/296/diabetes+130+us+hospitals+for+years+1999+2008) UCI \"Diabetes 130-US hospitals for years 1999-2008\" [1]\n",
    "\n",
    "The purpose of this project is to develop a prediction model for <30-day readmissions of diabetic patients. These readmissions can significantly impact Medicare billing, potentially leading to financial penalties for hospitals with high readmission rates. By identifying the key features used by the model to make its classifications, hospitals can develop informed treatment plans to reduce the likelihood of readmissions. Additionally, the model can be used in real-time to predict the probability of a patient\"s readmission, providing healthcare professionals with valuable insights for optimizing patient care.\n",
    "\n",
    "\n",
    "[1] Clore,John, Cios,Krzysztof, DeShazo,Jon & Strack,Beata. (2014). Diabetes 130-US hospitals for years 1999-2008. UCI Machine Learning Repository. https://doi.org/10.24432/C5230J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd        # Importing pandas library and renaming it to pd for convenience\n",
    "import pickle             # Importing the pickle library for reading in saved models later\n",
    "import numpy as np        # Importing numpy library and renaming it to np for convenience\n",
    "import matplotlib.pyplot as plt   # Importing matplotlib library and renaming it to plt for convenience\n",
    "import time               # Importing the time library for tracking the duration of certain operations\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # Setting pandas chained_assignment option to None to suppress warning messages\n",
    "\n",
    "seed = 42               # Setting a seed for reproducibility of randomization functions\n",
    "\n",
    "start_time = time.time()   # Setting a starting time for tracking the duration of certain operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")   # Setting the default style for Matplotlib to \"ggplot\"\n",
    "\n",
    "my_style = {   # Defining a custom style dictionary with new colors and formatting options\n",
    "    \"axes.prop_cycle\": plt.cycler(color=[\"#015bd3\", \"#fd5305\", \"#ffd2ea\"]),\n",
    "    \"text.color\": \"#191919\",\n",
    "    \"text.color\": \"#191919\",\n",
    "    \"xtick.color\": \"#191919\",\n",
    "    \"ytick.color\": \"#191919\",\n",
    "    \"axes.labelcolor\": \"#191919\",\n",
    "    \"legend.edgecolor\": \"white\",\n",
    "    \"axes.facecolor\": \"#ebecf0\",\n",
    "}\n",
    "\n",
    "# Setting the custom style for Matplotlib\n",
    "plt.style.use(my_style)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"dataset_diabetes/diabetic_data.csv\").replace(\"?\", np.nan)\n",
    "# Reading in the \"diabetic_data.csv\" file as a pandas DataFrame and storing it in the \"df_raw\" variable.\n",
    "# Replacing all \"?\" values in the DataFrame with NaN (missing) values using the replace() method.\n",
    "\n",
    "df_raw.head()\n",
    "# Displaying the first few rows of the DataFrame using the head() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info() # Display dataframe info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns composed of >30% nan values\n",
    "\n",
    "Before dropping nan values, I will drop the columns with a signifficant number of nan values.  This will increase the total number of data points after dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.weight.isna().value_counts(normalize=True)\n",
    "# Checking the percentage of missing values in the \"weight\" column of the DataFrame.\n",
    "# Using the isna() method to create a Boolean mask for NaN (missing) values in the column.\n",
    "# Using the value_counts() method to count the number of True/False values in the mask and normalize the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()   # Creating a copy of the original DataFrame to avoid modifying it directly.\n",
    "\n",
    "# Creating a list of column names to drop from the DataFrame based on a threshold of missing values.\n",
    "col_to_drop = list(df_raw.columns[df_raw.isna().sum() > len(df_raw) * 0.3])\n",
    "col_to_drop.remove(\"medical_specialty\")   # Removing the \"medical_specialty\" column from the list, as it was deemed important.\n",
    "\n",
    "list(col_to_drop)   # Displaying the list of column names to be dropped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Unused Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_meds = [\"examide\", \"citoglipton\", \"metformin-rosiglitazone\"]  # Creating a list of medication columns to be dropped as they only contain None values.\n",
    "\n",
    "df = df.drop(columns=col_to_drop + unused_meds + [\"encounter_id\", \"patient_nbr\"]).dropna()\n",
    "# Dropping columns that have been deemed unnecessary (col_to_drop and unused_meds),\n",
    "# as well as the \"encounter_id\" and \"patient_nbr\" columns which are patient identifiers and not relevant for the analysis.\n",
    "# Finally, dropping rows with missing values using the dropna() method.\n",
    "\n",
    "df.shape   # Displaying the new dimensions (shape) of the DataFrame after the columns and rows have been dropped. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove patients who died or were transferred to hospice\n",
    "\n",
    "These patients will not be readmitted and a model is not needed to determine that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.discharge_disposition_id.isin([11, 13, 14, 19, 20, 21, 26]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_raw = pd.read_csv(\"dataset_diabetes/IDs_mapping.csv\", header=None)\n",
    "\n",
    "admin_type_map = mappings_raw.iloc[0:9, :]\n",
    "discharge_type_map = mappings_raw.iloc[10:41, :]\n",
    "admin_source_map = mappings_raw.iloc[42:, :]\n",
    "\n",
    "dfs = [admin_type_map, discharge_type_map, admin_source_map]\n",
    "\n",
    "for _df in dfs:\n",
    "    _df.columns = _df.iloc[0]  # Renaming the columns with the first row values\n",
    "    _df.drop(_df.index[0], inplace=True)  # Dropping the first row as it is now redundant\n",
    "    _df.reset_index(drop=True, inplace=True)  # Resetting the index to start at 0 and drop the old index\n",
    "    _df.set_index(_df.columns[0], inplace=True)  # Setting the index to the first column\n",
    "    _df.loc[9] = [\"Other\"]  # Adding an \"Other\" category to replace IDs not in the mappings\n",
    "    \n",
    "admin_type_map  # Displaying the admin_type_map DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cats = [] # Store the names of these integer categorical columns for later use\n",
    "\n",
    "for _df in dfs:\n",
    "    # Get the mapping id values where the description is equivalent to other\n",
    "    nan_map = _df[_df.description.isin([\"Not Mapped\", \"Not Available\", \" Not Available\", \"Unknown/Invalid\", np.nan])]\n",
    "    col_name = _df.index.name\n",
    "    int_cats.append(col_name)\n",
    "\n",
    "    nan_id = nan_map.index.values.astype(int)\n",
    "    \n",
    "    # Replace the null values with \"Other\" category\n",
    "    df[col_name] = df[col_name].replace(nan_id, 9)\n",
    "\n",
    "# Count the number of values for each category in the \"admission_type_id\" column\n",
    "df.admission_type_id.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ADM_MERGED feature\n",
    "This combines the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the values of admission_type_id and medical_specialty columns separated by '_'\n",
    "df[\"ADM_MERGED\"] = df.admission_type_id.astype(str) + \"_\" + df.medical_specialty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Infrequent Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for infrequent values\n",
    "threshold = 0.005 # 0.5%\n",
    "\n",
    "# Iterate over specified columns and replace infrequent values with 9 for integers and 'other' for objects\n",
    "for col in [\"discharge_disposition_id\", \"admission_source_id\", \"medical_specialty\", \"ADM_MERGED\"]:\n",
    "    # Get infrequent values below the threshold\n",
    "    infrequent_vals = df[col].value_counts()[df[col].value_counts() < threshold * len(df)].index\n",
    "    \n",
    "    # Set replacement value based on column data type\n",
    "    repl = 9 if df[col].dtype == int else \"other\"\n",
    "    \n",
    "    # Replace infrequent values with replacement value\n",
    "    df[col] = df[col].replace(infrequent_vals, repl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with unknown or invalid gender and rename gender column to sex\n",
    "df = df[~(df.gender == \"Unknown/Invalid\")]\n",
    "df.rename({\"gender\":\"sex\"}, axis=1, inplace=True)\n",
    "\n",
    "# Convert sex to binary (0 = female, 1 = male)\n",
    "df.sex = df.sex.apply(lambda x: 0 if x == \"Female\" else 1)\n",
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"No\" values to 0 and \"Yes\" values to 1 for columns diabetesMed and change\n",
    "df.diabetesMed = df.diabetesMed.apply(lambda x: 0 if x == \"No\" else 1)\n",
    "df.change = df.change.apply(lambda x: 0 if x == \"No\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make age a continuous variable\n",
    "df.age = df.age.apply(lambda x: int(np.array(x[1:-1].split(\"-\")).astype(int).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert age to age groups\n",
    "def convert_age_to_group(age):\n",
    "    if age < 18: # If age is less than 18, return \"minor\"\n",
    "        return \"minor\"\n",
    "    elif age < 65: # If age is less than 65, return \"adult\"\n",
    "        return \"adult\"\n",
    "    else: # If age is greater than or equal to 65, return \"elderly\"\n",
    "        return \"elderly\"\n",
    "\n",
    "# Apply the function to the age column to create a new age_group column\n",
    "df[\"age_group\"] = df.age.apply(convert_age_to_group)\n",
    "\n",
    "# Display the value counts of the age_group column\n",
    "df.age_group.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnoses\n",
    "\n",
    "https://www.cms.gov/Medicare/Coding/ICD9ProviderDiagnosticCodes/codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize ICD9 codes\n",
    "def get_ICD9_category(value):\n",
    "        try:\n",
    "            num = int(float(value)) # convert input to float and then to int\n",
    "            if (num >=390 and num <=459 ) or num == 785: # Check if circulatory\n",
    "                category = \"circulatory\"\n",
    "            elif (num >= 460 and num <= 519) or num == 786: # Check if respiratory\n",
    "                category = \"respiratory\"\n",
    "            elif (num >= 520 and num <= 579) or num == 787: # Check if digestive\n",
    "                category = \"digestive\"\n",
    "            elif num==250: # Check if diabetes\n",
    "                category = \"diabetes\"\n",
    "            elif num >= 800 and num <= 999: # Check if injury\n",
    "                category = \"injury\"\n",
    "            elif num >= 710 and num <= 739: # Check if musculoskeletal\n",
    "                category = \"musculoskeletal\"\n",
    "            elif (num >= 580 and num <= 629) or num == 788: # Check if genitourinary\n",
    "                category = \"genitourinary\"\n",
    "            elif num >= 140 and num <= 239: # Check if neoplasms\n",
    "                category = \"neoplasms\"\n",
    "            else: # If none of the above, classify as \"other\"\n",
    "                category = \"other\"\n",
    "        except ValueError: # If the value cannot be converted to float or int, classify as \"other\"\n",
    "            category = \"other\"\n",
    "        \n",
    "        return category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the ICD9 categorization function if it has not already been done\n",
    "if not df.diag_1.isin([\"other\"]).any():\n",
    "    for num in range(1,4):\n",
    "        col_name = f\"diag_{num}\"\n",
    "        df[col_name] = df[col_name].apply(get_ICD9_category)\n",
    "\n",
    "        # print the column name and its value counts\n",
    "        print(col_name)\n",
    "        print(df[col_name].value_counts(normalize=True), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataframe to just the medication columns\n",
    "drugs = df.iloc[:, 19:39].copy()\n",
    "\n",
    "# Identify the columns that do not have exactly 4 unique values\n",
    "drugs_to_drop = drugs.columns[drugs.nunique() != 4]\n",
    "\n",
    "# Drop the columns from the original dataframe\n",
    "df.drop(columns=drugs_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the drugs columns in the dataframe\n",
    "num_changes = drugs.copy()\n",
    "\n",
    "# Iterate through each column in num_changes\n",
    "for col in num_changes:\n",
    "    \n",
    "    # Apply a lambda function to convert medication values to 0 if \"No\" or \"Steady\", 1 otherwise\n",
    "    num_changes[col] = num_changes[col].apply(lambda x: 0 if x in [\"No\", \"Steady\"] else 1)\n",
    "    \n",
    "# Sum the values in each row of num_changes and create a new column in df called \"num_med_changes\"\n",
    "df[\"num_med_changes\"] = num_changes.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review changes before proceeding\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adressing Class Imbalance via Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View normalized values to observe class imbalance\n",
    "df.readmitted.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target variable, convert to binary classification\n",
    "y = df.readmitted\n",
    "y = y.apply(lambda x: 1 if x == \"<30\" else 0)\n",
    "\n",
    "print(len(y)) # print number of samples\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "to_plot = y.value_counts() # get the count of each class\n",
    "bars = to_plot.plot(kind=\"bar\", ax=ax) # plot the counts as a bar chart\n",
    "for i, v in enumerate(to_plot):\n",
    "    ax.annotate(str(round(v / len(y) * 100)) + \"%\", xy=(i, v), ha=\"center\", va=\"bottom\") # add percentage labels to the bars\n",
    "\n",
    "ax.set_xticklabels([\">30D or No Readmin\", \"<30D Readmin\"], rotation=0) # label the x-axis\n",
    "\n",
    "fig.savefig(\"Presentation/Images/48657_before_undersamp.png\", dpi=300) # save the figure as an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Drop the target variable from X\n",
    "X = df.drop(columns=[\"readmitted\"])\n",
    "\n",
    "# Perform random undersampling to balance the classes\n",
    "X, y = RandomUnderSampler(random_state=seed, sampling_strategy=1.0).fit_resample(X, y)\n",
    "\n",
    "# Print the new length of y (the target variable)\n",
    "print(len(y))\n",
    "\n",
    "# Create a bar chart to visualize the class balance after undersampling\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "to_plot = y.value_counts()\n",
    "bars = to_plot.plot(kind=\"bar\", ax=ax)\n",
    "for i, v in enumerate(to_plot):\n",
    "    ax.annotate(str(round(v / len(y) * 100)) + \"%\", xy=(i, v), ha=\"center\", va=\"bottom\")\n",
    "ax.set_xticklabels([\">30D or No Readmin\", \"<30D Readmin\"], rotation=0)\n",
    "\n",
    "# Save the figure to a file\n",
    "fig.savefig(\"Presentation/Images/10816_after_undersamp.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all categorical columns (object) and the previously identified integer categorical columns (int_cats)\n",
    "cat_cols = X.select_dtypes(include=object).columns.to_list() + int_cats\n",
    "\n",
    "# Select all continuous columns by dropping the categorical columns from the dataframe\n",
    "cont_cols = X.drop(columns=cat_cols).columns.tolist()\n",
    "\n",
    "# Loop through each categorical column and ensure that it is represented as a string\n",
    "for column in cat_cols:\n",
    "    X.loc[:, column] = X[column].astype(str)\n",
    "\n",
    "# Create dummy variables for each categorical column and store it in a new dataframe called dummies\n",
    "dummies = pd.get_dummies(X[cat_cols])\n",
    "\n",
    "# Drop all categorical columns from the original dataframe\n",
    "X.drop(columns=cat_cols, inplace=True)\n",
    "\n",
    "# Join the dummies dataframe with the original dataframe\n",
    "X = X.join(dummies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=seed, stratify=y)\n",
    "\n",
    "# Instantiate the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the continuous columns in the training set\n",
    "X_train[cont_cols] = scaler.fit_transform(X_train[cont_cols])\n",
    "\n",
    "# Scale the continuous columns in the testing set\n",
    "X_test[cont_cols] = scaler.transform(X_test[cont_cols])\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for model evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a function to print classification metrics and confusion matrix\n",
    "def eval_model(model):\n",
    "    for label, y_true, _X in ((\"Train\", y_train, X_train), (\"Test\", y_test, X_test)):\n",
    "        y_pred = model.predict(_X)\n",
    "\n",
    "        fig, axes = plt.subplots(ncols=2, figsize=(10,4))\n",
    "        \n",
    "        # Display the classification report, which includes precision, recall, f1-score, and support\n",
    "        metrics = classification_report(y_true, y_pred)\n",
    "        ax=axes[1]\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0.5, 0.25, metrics, size=12, ha=\"center\", transform=ax.transAxes)\n",
    "\n",
    "        ax = axes[0]\n",
    "        # Create the confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        # Create confusion matrix plot, which shows the counts of true positives, false positives, true negatives, and false negatives\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"plasma\", ax=ax)\n",
    "        ax.set_ylabel(\"True label\")\n",
    "        ax.set_xlabel(\"Predicted label\")\n",
    "\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for computing class weights\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = [0.95, 1.0]\n",
    "class_weights_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library for RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier object with a fixed random_state for reproducibility\n",
    "rand_forest = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using the previously defined eval_model() function\n",
    "eval_model(rand_forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import clone\n",
    "\n",
    "# Clone the model and perform a grid search\n",
    "rand_forest_gscv = clone(rand_forest)\n",
    "\n",
    "# param_grid = {\n",
    "#     \"n_estimators\": [200, 500, 750],\n",
    "#     \"max_depth\": [None, 5, 7],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "#     \"min_samples_leaf\": [1, 2, 4],\n",
    "#     \"max_features\": [\"sqrt\", \"log2\"],\n",
    "#     \"bootstrap\": [True, False],\n",
    "#     \"class_weight\" : [\"balanced\", class_weights_dict]\n",
    "# }\n",
    "\n",
    "\n",
    "# grid_search = GridSearchCV(rand_forest_gscv, param_grid, scoring=\"roc_auc\", n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# grid_search.best_params_\n",
    "\n",
    "# eval_model(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"bootstrap\": True, # Whether or not to use bootstrapping to resample the dataset\n",
    "    \"class_weight\": {0: 0.9, 1: 1.0}, # Weight given to each class label in the loss function\n",
    "    \"max_depth\": 7, # Maximum depth of the decision trees in the forest\n",
    "    \"max_features\": \"sqrt\", # Maximum number of features to consider when looking for the best split\n",
    "    \"min_samples_leaf\": 1, # Minimum number of samples required in a leaf node\n",
    "    \"min_samples_split\": 2, # Minimum number of samples required to split an internal node\n",
    "    \"n_estimators\": 750 # Number of trees in the forest\n",
    "}\n",
    "\n",
    "# Set the hyperparameters of the random forest model\n",
    "rand_forest_gscv.set_params(**params)\n",
    "\n",
    "# Train the random forest model using the training data\n",
    "rand_forest_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model performance on the train and test data using the previously defined function\n",
    "eval_model(rand_forest_gscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for building a support vector machine model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate the support vector machine model with a specified random state\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "# Fit the support vector machine model to the training data\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the support vector machine model on the training and testing sets\n",
    "eval_model(svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clone of the support vector machine model\n",
    "svc_gscv = clone(svc)\n",
    "\n",
    "# Define the parameters to be used in the grid search\n",
    "params = {\n",
    "    \"kernel\" : \"rbf\",  # Kernel type used in the algorithm\n",
    "    \"gamma\" : \"scale\", # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "    \"class_weight\": {0:0.9, 1:1.0} # Set weight of the classes, the first value is for class 0 and the second for class 1\n",
    "}\n",
    "\n",
    "# Set the parameters for the support vector machine model\n",
    "svc_gscv.set_params(**params)\n",
    "\n",
    "# Train the support vector machine model with the grid search optimized parameters\n",
    "svc_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the support vector machine model using the evaluation function\n",
    "eval_model(svc_gscv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for building a LightGBM model\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Instantiate a LightGBM classifier model with a random state for reproducibility\n",
    "lgbm = LGBMClassifier(random_state=seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using the defined evaluation function\n",
    "eval_model(lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_gscv = clone(lgbm)\n",
    "\n",
    "# param_grid = {\n",
    "#     \"learning_rate\": [0.01, 0.1, 0.05],\n",
    "#     \"n_estimators\": [100, 500],\n",
    "#     \"max_depth\": [3, 5, None],\n",
    "#     \"num_leaves\": [5, 10, 20],\n",
    "#     \"min_child_samples\": [10, 20, 30],\n",
    "#     \"reg_lambda\": [0.0, 0.1, 0.5],\n",
    "#     \"colsample_bytree\": [0.5, 0.7, 0.9],\n",
    "#     \"subsample\": [0.5, 0.7, 0.9],\n",
    "#     \"class_weight\" : [\"balanced\", class_weights_dict]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(lgbm_gscv, param_grid, scoring=\"roc_auc\", n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# grid_search.best_params_\n",
    "\n",
    "# eval_model(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"class_weight\": {0: 0.9, 1: 1.0}, # Class weights to address imbalance\n",
    "    \"colsample_bytree\": 0.5, # fraction of columns to use at each split\n",
    "    \"learning_rate\": 0.05, # shrinkage rate for gradient descent\n",
    "    \"max_depth\": None, # maximum depth of tree (None = no limit)\n",
    "    \"min_child_samples\": 30, # minimum number of samples in a child (leaf) node\n",
    "    \"n_estimators\": 100, # number of trees to use\n",
    "    \"num_leaves\": 10, # maximum number of leaves in a tree\n",
    "    \"reg_lambda\": 0.0, # regularization parameter for L2 regularization\n",
    "    \"subsample\": 0.5 # fraction of rows to use at each split\n",
    "}\n",
    "\n",
    "# Set the model parameters to the best parameter combination found through grid search (uncomment this line to use)\n",
    "# params = grid_search.best_params_\n",
    "\n",
    "lgbm_gscv.set_params(**params) # set the parameters of the model\n",
    "lgbm_gscv.fit(X_train, y_train) # fit the model\n",
    "eval_model(lgbm_gscv) # evaluate the model using the defined evaluation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize the CatBoostClassifier model\n",
    "catboost = CatBoostClassifier(random_state=seed, verbose=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "catboost.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on both the training and testing data using the `eval_model` function\n",
    "eval_model(catboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_gscv = clone(catboost)\n",
    "\n",
    "# param_grid = {\n",
    "#     \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "#     \"n_estimators\": [100, 500, 1000],\n",
    "#     \"depth\": [3, 5, 7],\n",
    "#     \"l2_leaf_reg\": [0.0, 0.1, 0.5],\n",
    "#     \"colsample_bylevel\": [0.5, 0.7, 0.9],\n",
    "#     \"subsample\": [0.5, 0.7, 0.9],\n",
    "#     \"class_weights\" : [class_weights]\n",
    "# }\n",
    "# # \"roc_auc\"\n",
    "# grid_search = GridSearchCV(catboost_gscv, param_grid, scoring=\"roc_auc\", n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# grid_search.best_params_\n",
    "\n",
    "# eval_model(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"class_weights\": [0.94, 1.0],  # weights for each class, with a higher weight assigned to the minority class\n",
    "    \"colsample_bylevel\": 0.5,  # fraction of columns to subsample at each split level\n",
    "    \"depth\": 5,  # depth of the tree\n",
    "    \"l2_leaf_reg\": 0.1,  # L2 regularization coefficient for leaf weights\n",
    "    \"learning_rate\": 0.01,  # learning rate for gradient descent\n",
    "    \"n_estimators\": 1000,  # number of trees to build\n",
    "    \"subsample\": 0.7  # fraction of rows to subsample at each split level\n",
    "}\n",
    "\n",
    "# Set the hyperparameters for the CatBoost model using GridSearchCV\n",
    "catboost_gscv.set_params(**params)\n",
    "\n",
    "# Fit the CatBoost model with the training data\n",
    "catboost_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the CatBoost model with the eval_model function\n",
    "eval_model(catboost_gscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(_history, _model, _test_data=X_test, y_true=y_test):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10,8))\n",
    "\n",
    "    # Generate predictions on the test data\n",
    "    y_pred = _model.predict(_test_data)\n",
    "\n",
    "    if y_pred.shape[1] == 1:\n",
    "        y_pred = list((y_pred > 0.5).astype(int))\n",
    "    else:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # Print model metrics report\n",
    "    metrics = classification_report(y_true, y_pred)\n",
    "    ax=axes[1][1]\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(0.5, 0.25, metrics, size=12, ha=\"center\", transform=ax.transAxes)\n",
    "\n",
    "    # Generate a confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Plot the confusion matrix\n",
    "    ax=axes[1][0]\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"plasma\", ax=ax)\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "\n",
    "    # Plot the training and validation accuracy\n",
    "    ax = axes[0][0]\n",
    "\n",
    "    ax.plot(_history.history[\"accuracy\"])\n",
    "    ax.plot(_history.history[\"val_accuracy\"])\n",
    "    ax.set_title(\"Model Accuracy\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.legend([\"Train\", \"Val\"])\n",
    "\n",
    "    # Plot the training and validation loss\n",
    "    ax = axes[0][1]\n",
    "    ax.plot(_history.history[\"loss\"])\n",
    "    ax.plot(_history.history[\"val_loss\"])\n",
    "    ax.set_title(\"Model Loss\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.legend([\"Train\", \"Val\"])\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import Sequential\n",
    "# from keras.layers import Dense, Dropout, BatchNormalization, Dropout, Bidirectional\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l1,l2\n",
    "\n",
    "# # Define a sequential model using Keras\n",
    "# model = Sequential([\n",
    "#     Dense(64, \"relu\", input_dim=X_train.shape[1]), # Input layer with 64 neurons and \"relu\" activation function\n",
    "#     BatchNormalization(), # Batch normalization layer to normalize activations\n",
    "#     Dropout(0.2), # Dropout layer to prevent overfitting by randomly dropping out 20% of the neurons\n",
    "#     Dense(32, \"relu\", kernel_regularizer=l2(0.01)), # Hidden layer with 32 neurons and \"relu\" activation function with L2 regularization (0.01)\n",
    "#     Dropout(0.2), # Another dropout layer to prevent overfitting\n",
    "#     Dense(32, \"relu\", kernel_regularizer=l2(0.01)), # Another hidden layer with 32 neurons and \"relu\" activation function with L2 regularization (0.01)\n",
    "#     Dense(16, \"relu\"), # Another hidden layer with 16 neurons and \"relu\" activation function\n",
    "#     Dense(1, \"sigmoid\") # Output layer with 1 neuron and \"sigmoid\" activation function (binary classification)\n",
    "# ])\n",
    "\n",
    "# # Compile the model with Adam optimizer (with a learning rate of 1e-4), binary_crossentropy loss function, and accuracy and recall as evaluation metrics\n",
    "# model.compile(Adam(1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"Recall\"])\n",
    "\n",
    "# # Train the model with training and validation sets, with batch size 32 and 50 epochs, and add EarlyStopping callback to stop training if validation loss doesn't improve for 6 consecutive epochs\n",
    "# history = model.fit(\n",
    "#     X_train.values, y_train.values, \n",
    "#     batch_size=32, \n",
    "#     epochs=50, \n",
    "#     validation_data=(X_test.values, y_test.values),\n",
    "#     callbacks=[\n",
    "#         EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)],\n",
    "#     class_weight={0:.93, 1:1.0} # Set class weights to address class imbalance in the dataset\n",
    "# )\n",
    "\n",
    "# # Save the trained model and history to files for future use\n",
    "# model.save(\"RNN_info/RNN.h5\")\n",
    "# with open(\"RNN_info/RNN_history.pickle\", \"wb\") as file:\n",
    "#     pickle.dump(history, file)\n",
    "\n",
    "# # Analyze and visualize the training history of the model\n",
    "# analyze_model(history, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model and history\n",
    "model = load_model(\"RNN_info/RNN.h5\")\n",
    "with open(\"RNN_info/RNN_history.pickle\", \"rb\") as file:\n",
    "    history = pickle.load(file)\n",
    "\n",
    "# Evaluate the model and display metrics\n",
    "analyze_model(history, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's Perfromance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# Define a list of models to evaluate\n",
    "models = [rand_forest_gscv, svc_gscv, lgbm_gscv, catboost_gscv, model]\n",
    "\n",
    "# Define a list of model names for display purposes\n",
    "model_names = [\"Random Forest\", \"SVC\", \"LightGBM\", \"CatBoost\", \"Recurrent Neural Net\"]\n",
    "\n",
    "# Create empty lists to store the evaluation metrics for each model\n",
    "accs, target_f1s, avg_f1s = [], [], []\n",
    "\n",
    "# Loop through each model to evaluate its performance\n",
    "for _model in models:\n",
    "    # Make predictions on the test data using the current model\n",
    "    preds = _model.predict(X_test)\n",
    "    preds = list((preds > 0.5).astype(int))\n",
    "\n",
    "    # Calculate the precision, recall, and F1-score for each class (0 and 1)\n",
    "    precision, recall, f1_score, support  = precision_recall_fscore_support(y_test, preds,)\n",
    "    \n",
    "    # Calculate the accuracy score\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    \n",
    "    # Extract the F1-score for the positive class (class 1)\n",
    "    target_f1 = f1_score[1]\n",
    "    \n",
    "    # Calculate the average F1-score across both classes\n",
    "    avg_f1 = f1_score.mean()\n",
    "\n",
    "    # Append the evaluation metrics for the current model to their respective lists\n",
    "    accs.append(round(acc*100))\n",
    "    target_f1s.append(round(target_f1*100))\n",
    "    avg_f1s.append(round(avg_f1*100))\n",
    "\n",
    "# Define a list of the evaluation metrics to display in the bar chart\n",
    "metrics = [\"Accuracy\", \"Target F1-Score\", \"Average F1-Score\"]\n",
    "\n",
    "# Create variables to set the position and width of each bar in the bar chart\n",
    "x_pos = np.arange(len(model_names))\n",
    "width = 0.2\n",
    "\n",
    "# Create a bar chart to display the evaluation metrics for each model\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.bar(x_pos - width, accs, width, label=\"Accuracy\")\n",
    "ax.bar(x_pos + width, target_f1s, width, label=\"Target F1-Score\")\n",
    "ax.bar(x_pos, avg_f1s, width, label=\"Average F1-Score\")\n",
    "\n",
    "# Set the x-tick labels to the model names and display them vertically\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(model_names, rotation=90)\n",
    "\n",
    "# Set the y-label to \"Score\"\n",
    "ax.set_ylabel(\"Score\")\n",
    "\n",
    "# Add a legend to the chart\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "# Annotate each bar with its respective value\n",
    "for i, v in enumerate(accs):\n",
    "    ax.annotate(str(v) + \"%\", xy=(i-width, v), ha=\"center\", va=\"bottom\")\n",
    "for i, v in enumerate(target_f1s):\n",
    "    ax.annotate(str(v) + \"%\", xy=(i+width, v), ha=\"center\", va=\"bottom\")\n",
    "for i, v in enumerate(avg_f1s):\n",
    "    ax.annotate(str(v) + \"%\", xy=(i, v), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Adjust the layout of the figure to prevent overlapping text\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figure to a file\n",
    "fig.savefig(\"Presentation/Images/ModelComparison.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define replacements for string preprocessing of labels\n",
    "replacements = (\n",
    "    (\"discharge_disposition_id_3\", \"Discharged to SNF\"),\n",
    "    (\"discharge_disposition_id_1\", \"Discharged to Home\"),\n",
    "    (\"discharge_disposition_id_22\", \"Discharged to Rehab\"),\n",
    "    (\"num_\", \"number_\"), # Rename columns starting with \"num_\" to \"number_\"\n",
    "    (\"ADM_MERGED_2\", \"Urgent Care to\"), # Replace ADM_MERGED_2 with \"Urgent Care to\"\n",
    "    (\"diabetesMed\", \"On Diabetes Meds\") # Replace diabetesMed with \"On Diabetes Meds\"\n",
    ")\n",
    "\n",
    "# Function to preprocess labels\n",
    "def prep_label(string):\n",
    "    for to, repl in replacements:\n",
    "        string = string.replace(to, repl)\n",
    "    \n",
    "    return string.replace(\"_\", \" \").title()\n",
    "\n",
    "\n",
    "# Calculate feature importances and select the top 11 features\n",
    "importances = pd.Series(rand_forest_gscv.feature_importances_, X_train.columns)\n",
    "_X = pd.concat([X_train, X_test])\n",
    "_y = pd.concat([y_train, y_test])\n",
    "important_feats = importances.sort_values(ascending=True)[-11:]\n",
    "\n",
    "# Plot the feature importances\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.vlines([0], len(important_feats), -1, colors=\"#fd5305\") # Add vertical line to show the importance cutoff\n",
    "ax.tick_params(axis='y', which='major', labelsize=12) # Adjust y-axis tick label size\n",
    "(important_feats * _X.corrwith(y)[important_feats.index].apply(lambda x: -1 if x < 0 else 1)).plot(kind=\"barh\", ax=ax) # Plot the feature importances\n",
    "labels = [prep_label(label) for label in important_feats.index] # Apply label preprocessing\n",
    "ax.set_yticklabels(labels) # Set y-tick labels\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"Presentation/Images/lgbm_importances.png\", dpi=300) # Save the plot as a PNG file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependance of Discharge Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = pd.concat([X_train, X_test]).median()\n",
    "discharge_ids = _X.index[_X.index.str.contains(\"discharge_disposition_id\")]\n",
    "_X.loc[discharge_ids] = 0\n",
    "\n",
    "preds = pd.Series(dtype=float)\n",
    "\n",
    "for id in discharge_ids:\n",
    "    x = _X.copy()\n",
    "    x.loc[id] = 1\n",
    "    x = np.reshape(x.values, (1, -1))\n",
    "\n",
    "    pred = lgbm_gscv.predict_proba(x)\n",
    "\n",
    "    id = id.split(\"_\")[-1]\n",
    "    name = discharge_type_map.loc[id].description\n",
    "    preds.loc[name] = pred[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.sort_values(inplace=True)\n",
    "preds.index = [\"Home\", \"Home with Health Service\", \"ICF\", \"Left AMA\", \"Inpatient at Same Hospital\", \"Different Short-Term Hospital\", \"SNF\", \"Inpatient at Different Hospital\", \"Rehab or In-House Rehab\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "preds.plot(kind=\"barh\", ax=ax)\n",
    "ax.set_xlabel(\"predicted probability of readmission\".title())\n",
    "ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "# ax.set_yticklabels(ax.get_yticklabels(), rotation=30)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"Presentation/Images/DischargeTypes.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,13))\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(rand_forest_gscv, X, important_feats.index, ax=ax, kind=\"both\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def alert(title=\"title\", text=\"text\"):\n",
    "    os.system(\"\"\"\n",
    "              osascript -e 'display alert \"{}\" message \"{}\"'\n",
    "              \"\"\".format(title, text))\n",
    "\n",
    "# Alert me when notebook is finished so that I can multitask\n",
    "total_time = (time.time() - start_time) / 60 \n",
    "    \n",
    "alert(\"Notebook Completed!\", f\"Completed in {total_time} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
